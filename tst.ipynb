{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c55732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.mask import Mask\n",
    "from utils.VAD import SpeechVADTranscriber\n",
    "import tqdm as notebook_tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccc029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Acer/.cache\\torch\\hub\\snakers4_silero-vad_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "transcriber = SpeechVADTranscriber(\n",
    "    whisper_model_size=\"turbo\"\n",
    ")  # \"tiny\", \"base\", \"small\", \"medium\", \"large\", \"turbo\"\n",
    "mask = Mask(t5_model=\"base\")  # \"small\", \"base\", \"large\", \"3b\", \"11b\"\n",
    "print(\"Models loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b491731",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_paths = [\n",
    "    \"sample_audio/sample.mp3\",\n",
    "    \"sample_audio/output_muted.mp3\",\n",
    "    \"sample_audio/output_muted_400.mp3\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad67ba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcript =  [MASK] A quick brown fox jumps over the lazy dog [MASK]\n",
      "Reconstructed sentence: . A quick brown fox jumps over the lazy dog .\n",
      "transcript =  There's not an app for the most complex [MASK] life, which is falling in love. You know, it's funny because you know exactly what it is, but you can't simulate it. You can't predict it. You can't [MASK]\n",
      "Reconstructed sentence: There's not an app for the most complex part of life, which is falling in love. You know, it's funny because you know exactly what it is, but you can't simulate it. You can't predict it. You can't predict it.\n",
      "transcript =  There's not an app for the most complex [MASK] which is falling in love. You know, it's funny because you know exactly what it is, but you can't simulate it. You can't predict it [MASK]\n",
      "Reconstructed sentence: There's not an app for the most complex of things, which is falling in love. You know, it's funny because you know exactly what it is, but you can't simulate it. You can't predict it .\n"
     ]
    }
   ],
   "source": [
    "for each in audio_file_paths:\n",
    "    try:\n",
    "        # Process the audio file\n",
    "\n",
    "        transcription = transcriber.process_audio_file(\n",
    "            each,\n",
    "            vad_threshold=0.4,  # Adjust sensitivity (0.0-1.0)\n",
    "            min_speech_duration_ms=250,  # Minimum speech duration\n",
    "            min_silence_duration_ms=100,  # Minimum silence duration\n",
    "        )\n",
    "\n",
    "        print(\"transcript = \", transcription)\n",
    "\n",
    "        result = mask.fill_masks(transcription)\n",
    "        print(f\"Reconstructed sentence: {result}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Audio file '{each}' not found.\")\n",
    "        print(\"Please update the audio_file_path variable with a valid audio file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
